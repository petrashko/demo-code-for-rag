{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#\n",
    "#from langchain.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "sep = os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = hf_token\n",
    "# LangSmith tracking\n",
    "#os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "#\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заменить OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "#model_kwargs = {'device': 'cuda'}\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_id,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Progi\\PythonProg\\NLP\\RAG\\SunnySavita\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#model_id = 'sentence-transformers/all-MiniLM-l6-v2'\n",
    "model_id = 'BAAI/bge-m3'\n",
    "\n",
    "#model_args = {'device': 'cuda'}\n",
    "model_args = {'device': 'cpu'}\n",
    "\n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_id,\n",
    "    model_kwargs=model_args,\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, list)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loder = TextLoader(f'..{sep}data{sep}speech.txt', encoding='utf-8')\n",
    "document = loder.load()\n",
    "len(document), type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(document[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, list)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_documents(document)\n",
    "len(text_chunks), type(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сейчас наш момент встретить и преодолеть вызовы нашего времени.\n",
      "\n",
      "И мы сделаем это, как один народ.\n",
      "\n",
      "Одна Америка.\n",
      "\n",
      "Соединенные Штаты Америки.\n",
      "\n",
      "Да благословит вас всех Бог. Да защитит Бог наши войска.\n"
     ]
    }
   ],
   "source": [
    "#print(text_chunks[0].page_content); print(end='\\n\\n\\n')\n",
    "print(text_chunks[98].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(text_chunks, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template = '''\n",
    "Ты - Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\n",
    "Используй следующие фрагменты релевантного контекста, чтобы ответить на вопрос.\n",
    "Если ты не знаешь ответ, просто скажи, что не знаю.\n",
    "Используй максимум двадцать предложений и сделай ответ кратким.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(promt_template)\n",
    "retriever = vectorstore.as_retriever()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#llm_model = Ollama(model='sutyrin/saiga_mistral_7b', base_url='http://localhost:11434')\n",
    "llm_model = OllamaLLM(model='sutyrin/saiga_mistral_7b', base_url='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {'context': retriever,  'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'США оказывают поддержку Украине в экономическом и военном отношении. Военная помощь включает прямую финансовую поддержку, а также предоставление вооружения и оборудования. Экономическая помощь заключается в выделении более 1 миллиарда долларов США в качестве прямой помощи Украине. Также США оказывают гуманитарную поддержку, например, помогая украинскому народу облегчить его страдания.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('Какую поддержку США оказывают Украине в экономическом и военном отношении?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'США предпринимают следующие действия для решения проблемы роста цен на газ:\\n1. Сотрудничество с 30 другими странами для высвобождения 60 миллионов баррелей нефти из резервов по всему миру.\\n2. Высвобождение 30 миллионов баррелей из национального Стратегического нефтяного резерва США.\\n3. Развитие инфраструктуры и инноваций в Америке для производства большего количества автомобилей и полупроводников.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('Какие действия предпринимают США для решения проблемы роста цен на газ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
